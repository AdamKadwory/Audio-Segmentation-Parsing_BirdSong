{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import scipy.io \n",
    "import librosa \n",
    "import librosa.display \n",
    "import librosa as lr \n",
    "import wave\n",
    "from glob import glob  #for reading files \n",
    "import glob \n",
    "import pickle as pk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the bird, session, .wav files \n",
    "path_bird = '/Users/ahmedabdalsattar/Desktop/bird12/'\n",
    "path_session = os.listdir(path_bird)\n",
    "\n",
    "# parameters given \n",
    "hop_length = 512\n",
    "n_fft = 512\n",
    "window_size = 1048\n",
    "sampling_rate = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird_name:bird12 session:2020-08-13\n",
      "bird_name:bird12 session:2020-08-12\n"
     ]
    }
   ],
   "source": [
    "# parameters given \n",
    "hop_length = 512\n",
    "n_fft = 512\n",
    "window_size = 1048\n",
    "sampling_rate = 15000\n",
    "\n",
    "data = {\n",
    "    \"session_num\":[],\n",
    "    \"mfcc_vectors\":[],\n",
    "    \"labels\":[]\n",
    "\n",
    "}\n",
    "\n",
    "for session in path_session:\n",
    "    if session == '.DS_Store': #sometimes this happen only for mac where DS_store automatically created \n",
    "        pass \n",
    "    else:\n",
    "        wav_length = []\n",
    "        short_wav_length = []\n",
    "        mfcc_array = []\n",
    "        session_array = os.path.join(path_bird,session)\n",
    "        path_folder = session_array.strip(\"/\").split(\"/\")\n",
    "        print(\"bird_name:{bird} session:{session}\".format(bird=path_folder[-2],session=path_folder[-1]))\n",
    "        data[\"session_num\"].append(path_folder[-1])\n",
    "        wave_files = glob.glob(os.path.join(session_array,'*.wav'))\n",
    "        for i in range(len(wave_files)):\n",
    "            audio_array,sr = lr.load(wave_files[i],sr=sampling_rate)\n",
    "            time_period = lr.get_duration(filename=wave_files[i])\n",
    "            if time_period >= 1:\n",
    "                wav_length.append(time_period)\n",
    "                audio_array,sr = lr.load(wave_files[i],sr=sampling_rate)\n",
    "                mfcc = lr.feature.mfcc(audio_array, sr=sampling_rate,\n",
    "                                            n_fft=n_fft,hop_length=hop_length)\n",
    "                mfcc = mfcc.T\n",
    "                mfcc_array.append(mfcc)\n",
    "                data[\"mfcc_vectors\"].append(mfcc_array)\n",
    "            else:\n",
    "                short_wav_length.append(time_period)\n",
    "                pass \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for this function, i have to set a path for the folder where all labels are located\n",
    "or find all the files that endwith .txt as it represent the labels\n",
    "- for now the labels are all stored in one folder, include each .txt for each session\"\"\"\n",
    "\n",
    "labels = []\n",
    "path_labels = '/Users/ahmedabdalsattar/Desktop/labels/'\n",
    "\n",
    "txt_files = os.listdir(path_labels)\n",
    "labels = []\n",
    "for file in range(len(txt_files)):\n",
    "    path = os.path.join(path_labels,txt_files[file])\n",
    "    a = os.path.basename(path[-1])\n",
    "    if a == 't':\n",
    "        x = open(path,\"r\")\n",
    "        for line in x.readlines():\n",
    "            for i in line.split():\n",
    "                labels.append(int(i)) \n",
    "                \n",
    "    \n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "data[\"labels\"].append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data_mfcc.txt','wb') as pickle_file:\n",
    "#     pickle.dump(data,pickle_file)\n",
    "\n",
    "\n",
    "# with open('data_mfcc.txt','rb') as pickle_file:\n",
    "#     new_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert classes and labels into numpy arrays \n",
    "x = np.array(data[\"mfcc_vectors\"])\n",
    "y = np.array(data[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this function is to split the data into training and testing dataset\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs_train,inputs_test, targets_train,targets_test = train_test_split(x,y,test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(x.shape)),\n",
    "    \n",
    "    keras.layers.Dense(512,activation=\"relu\"),\n",
    "    \n",
    "    keras.layers.Dense(256,activation=\"relu\"),\n",
    "    \n",
    "    keras.layers.Dense(64,activation=\"relu\"),\n",
    "    \n",
    "    #output layer \n",
    "    keras.layers.Dense(10,activation=\"softmax\")\n",
    "     \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 536)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               274944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 423,370\n",
      "Trainable params: 423,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(inputs_train,targets_train,\n",
    "         validation_data=(inputs_test,targets_test),epochs=50,\n",
    "          batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
